{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb9b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating temporal usage patterns for 1 user...\n",
      "Generating engagement depth indicators for 1 user...\n",
      "Generating content consumption patterns for 1 user...\n",
      "Generating behavioral triggers for 1 user...\n",
      "Generating wellbeing indicators for 1 user...\n",
      "Saved temporal_patterns with 204 records for single user\n",
      "Saved engagement_depth with 300 records for single user\n",
      "Saved content_consumption with 300 records for single user\n",
      "Saved behavioral_triggers with 300 records for single user\n",
      "Saved wellbeing_indicators with 30 records for single user\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_temporal_usage_patterns(days=30):\n",
    "    \"\"\"Generate temporal usage patterns\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # User-specific patterns\n",
    "    base_sessions_per_day = np.random.gamma(2, 3)  # 2-20 sessions/day\n",
    "    weekend_multiplier = np.random.uniform(1.2, 2.0)  # More usage on weekends\n",
    "    \n",
    "    for day in range(days):\n",
    "        is_weekend = day % 7 in [5, 6]\n",
    "        sessions_today = int(base_sessions_per_day * (weekend_multiplier if is_weekend else 1))\n",
    "        \n",
    "        # Generate sessions for this day\n",
    "        session_times = np.random.uniform(0, 24, sessions_today)\n",
    "        \n",
    "        for session_time in session_times:\n",
    "            # Session duration (log-normal distribution, 1-60 minutes)\n",
    "            duration = np.random.lognormal(2.5, 1.2)  \n",
    "            duration = np.clip(duration, 1, 120)  # 1-120 minutes\n",
    "            \n",
    "            # Time between sessions\n",
    "            time_since_last = np.random.exponential(2)  # Hours\n",
    "            \n",
    "            # Peak usage hours (evening bias)\n",
    "            if 18 <= session_time <= 23:\n",
    "                duration *= np.random.uniform(1.5, 2.5)\n",
    "            \n",
    "            data.append({\n",
    "                'day': day,\n",
    "                'session_start_hour': session_time,\n",
    "                'session_duration_minutes': duration,\n",
    "                'time_since_last_session_hours': time_since_last,\n",
    "                'is_weekend': is_weekend\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_engagement_depth_indicators(n_sessions=300):\n",
    "    \"\"\"Generate engagement depth indicators\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for session_id in range(n_sessions):\n",
    "        # User type influences behavior\n",
    "        user_type = np.random.choice(['casual', 'moderate', 'heavy'], p=[0.4, 0.4, 0.2])\n",
    "        \n",
    "        # Scroll velocity (posts per minute)\n",
    "        if user_type == 'casual':\n",
    "            scroll_velocity = np.random.gamma(2, 2)  # Slower scrolling\n",
    "        elif user_type == 'moderate':\n",
    "            scroll_velocity = np.random.gamma(3, 3)\n",
    "        else:  # heavy user\n",
    "            scroll_velocity = np.random.gamma(5, 4)  # Faster scrolling\n",
    "            \n",
    "        # Scroll depth (relative to feed length)\n",
    "        scroll_depth = np.random.beta(2, 3)  # Most users don't scroll to bottom\n",
    "        \n",
    "        # Content interaction rate (interactions per 100 posts viewed)\n",
    "        base_interaction_rate = np.random.beta(2, 8) * 20  # 0-20%\n",
    "        \n",
    "        # Time spent per post (seconds)\n",
    "        time_per_post = np.random.lognormal(1.5, 0.8)\n",
    "        time_per_post = np.clip(time_per_post, 1, 60)\n",
    "        \n",
    "        # Return-to-feed frequency (times per session)\n",
    "        return_frequency = np.random.poisson(3)\n",
    "        \n",
    "        data.append({\n",
    "            'session_id': session_id,\n",
    "            'user_type': user_type,\n",
    "            'scroll_velocity_posts_per_min': scroll_velocity,\n",
    "            'scroll_depth_percentage': scroll_depth * 100,\n",
    "            'interaction_rate_percentage': base_interaction_rate,\n",
    "            'time_per_post_seconds': time_per_post,\n",
    "            'return_to_feed_frequency': return_frequency\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_content_consumption_patterns(n_sessions=300):\n",
    "    \"\"\"Generate content consumption patterns\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    content_types = ['photo', 'video', 'story', 'reel', 'text']\n",
    "    content_categories = ['lifestyle', 'news', 'entertainment', 'sports', 'politics', 'wellness']\n",
    "    \n",
    "    for session_id in range(n_sessions):\n",
    "        # User preferences\n",
    "        preferred_type = np.random.choice(content_types)\n",
    "        preferred_categories = np.random.choice(content_categories, size=2, replace=False)\n",
    "        \n",
    "        # Content type distribution\n",
    "        type_probs = [0.2] * len(content_types)\n",
    "        type_probs[content_types.index(preferred_type)] = 0.4\n",
    "        type_consumed = np.random.choice(content_types, p=np.array(type_probs)/sum(type_probs))\n",
    "        \n",
    "        # Time on negative/controversial content\n",
    "        negative_content_time = np.random.exponential(5)  # Minutes\n",
    "        \n",
    "        # Recommendation algorithm engagement\n",
    "        algo_clicks = np.random.poisson(8)\n",
    "        \n",
    "        # Search vs feed browsing ratio\n",
    "        search_ratio = np.random.beta(1, 4)  # Most time in feed, some searching\n",
    "        \n",
    "        data.append({\n",
    "            'session_id': session_id,\n",
    "            'primary_content_type': type_consumed,\n",
    "            'preferred_categories': ','.join(preferred_categories),\n",
    "            'negative_content_minutes': negative_content_time,\n",
    "            'algorithm_interactions': algo_clicks,\n",
    "            'search_vs_feed_ratio': search_ratio\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_behavioral_triggers(n_sessions=300):\n",
    "    \"\"\"Generate behavioral trigger data\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    trigger_types = ['notification', 'boredom', 'habit', 'social', 'news_check']\n",
    "    \n",
    "    for session_id in range(n_sessions):\n",
    "        # Notification response pattern\n",
    "        notification_delay = np.random.lognormal(1, 1.5)  # Minutes to respond\n",
    "        notification_delay = np.clip(notification_delay, 0.1, 120)\n",
    "        \n",
    "        # Trigger for opening app\n",
    "        opening_trigger = np.random.choice(trigger_types, \n",
    "                                         p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
    "        \n",
    "        # Background app usage (0-1 scale)\n",
    "        background_usage = np.random.beta(2, 5)\n",
    "        \n",
    "        # How session ended\n",
    "        exit_type = np.random.choice(['intentional', 'distracted', 'forced'], \n",
    "                                   p=[0.4, 0.4, 0.2])\n",
    "        \n",
    "        data.append({\n",
    "            'session_id': session_id,\n",
    "            'notification_response_minutes': notification_delay,\n",
    "            'opening_trigger': opening_trigger,\n",
    "            'background_usage_score': background_usage,\n",
    "            'exit_behavior': exit_type\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_wellbeing_indicators(days=30):\n",
    "    \"\"\"Generate wellbeing indicator data\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # User baseline characteristics\n",
    "    baseline_compulsiveness = np.random.beta(2, 5)  # Most users low, some high\n",
    "    baseline_sleep_quality = np.random.normal(7, 1.5)  # Hours of sleep\n",
    "    \n",
    "    for day in range(days):\n",
    "        # Usage exceeding planned time\n",
    "        planned_time = np.random.uniform(30, 120)  # Minutes planned\n",
    "        actual_time = planned_time * np.random.lognormal(0, 0.5)  # Usually more\n",
    "        time_overage = max(0, actual_time - planned_time)\n",
    "        \n",
    "        # Late night usage\n",
    "        late_night_minutes = np.random.exponential(15) if np.random.random() < 0.3 else 0\n",
    "        \n",
    "        # Compulsive checking\n",
    "        daily_compulsive_checks = np.random.poisson(baseline_compulsiveness * 20)\n",
    "        \n",
    "        # Sleep impact\n",
    "        sleep_hours = baseline_sleep_quality - (late_night_minutes / 60) * 0.5\n",
    "        sleep_hours = np.clip(sleep_hours, 4, 10)\n",
    "        \n",
    "        data.append({\n",
    "            'day': day,\n",
    "            'planned_usage_minutes': planned_time,\n",
    "            'actual_usage_minutes': actual_time,\n",
    "            'usage_overage_minutes': time_overage,\n",
    "            'late_night_usage_minutes': late_night_minutes,\n",
    "            'compulsive_checks_count': daily_compulsive_checks,\n",
    "            'sleep_hours': sleep_hours,\n",
    "            'baseline_compulsiveness': baseline_compulsiveness\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_single_user_social_media_dataset():\n",
    "    \"\"\"Generate a complete synthetic social media usage dataset for 1 user\"\"\"\n",
    "    \n",
    "    print(\"Generating temporal usage patterns for 1 user...\")\n",
    "    temporal_data = generate_temporal_usage_patterns()\n",
    "    \n",
    "    print(\"Generating engagement depth indicators for 1 user...\")\n",
    "    engagement_data = generate_engagement_depth_indicators()\n",
    "    \n",
    "    print(\"Generating content consumption patterns for 1 user...\")\n",
    "    content_data = generate_content_consumption_patterns()\n",
    "    \n",
    "    print(\"Generating behavioral triggers for 1 user...\")\n",
    "    trigger_data = generate_behavioral_triggers()\n",
    "    \n",
    "    print(\"Generating wellbeing indicators for 1 user...\")\n",
    "    wellbeing_data = generate_wellbeing_indicators()\n",
    "    \n",
    "    return {\n",
    "        'temporal_patterns': temporal_data,\n",
    "        'engagement_depth': engagement_data,\n",
    "        'content_consumption': content_data,\n",
    "        'behavioral_triggers': trigger_data,\n",
    "        'wellbeing_indicators': wellbeing_data\n",
    "    }\n",
    "\n",
    "# Generate the datasets for single user\n",
    "datasets = generate_single_user_social_media_dataset()\n",
    "\n",
    "# Save to CSV files\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f'synthetic_{name}_single_user.csv', index=False)\n",
    "    print(f\"Saved {name} with {len(df)} records for single user\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
